<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Marginalization in VINS</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<!-- <meta charset="utf-8"> -->
		<meta name="viewport" content="width=device-width">
		<!-- <title>MathJax example</title> -->
		<!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
		<script>MathJax = {
			tex:{
					inlineMath: [['$', '$'], ['\\(', '\\)']],
					tags: 'ams'
				},
			svg:{
					fontCache: 'global'
				},
            options:{enableMenu: false},
            renderActions: {
                    addMenu: [0, '', '']
                },
            // loader: {load: ['ui/lazy']}
		};
		</script>
		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
		<script id="MathJax-script" async
				src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js?config=TeX-AMS_HTML-full">
		</script>
	</head>
	<body class="is-preload">

		<!-- Main -->
			<div id="main" class="submain">
					<section id="study" class="subsection">
						<div class="container">

							<header>
								<h2 class="center">VINS中的边缘化</h2>
							</header>
								<h3>1.什么是边缘化</h3>
								<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
                                    边缘化，总结为一句话就是从联合概率分布中求边际概率。即
                                    \begin{equation}
                                        P(X=x) = \int_{ -\infty}^{\infty}  P(X=x, Y=y) dy 
                                    \end{equation}
                                    具体到vins系统中，为了维护变量的维度可控以达到实时性，我们常常维护一个固定长度的滑窗。当窗口进行滑动时，某些旧的变量需要被舍弃，
                                    这个舍弃的过程就牵扯到了边缘化。
                                </p>

                                <p style="text-indent:2em;margin-top:0em;margin-bottom:0em;font-size:0.9em;">
                                    考虑一个长度为4的变量窗口，
                                    在$t=2$的时刻，$X=[x_0, x_1, x_2]$。$t=3$时来一个新的变量$x_3$，我们把$x_3$加入到变量窗口里，
                                    并对变量$X_{old}=[x_0, x_1, x_2, x_3]$进行估计，这时我们得到了关于变量$x_i, i=1,2,3,4$的联合概率分布。
                                    而后，我们舍弃掉变量$x_0$，
                                    保留关于变量$X_{new}=[x_1, x_2, x_3]$的联合概率分布，这个舍弃就是通过边缘化来实现的。
                                    \begin{equation}
                                    \begin{aligned}
                                        P(X_{new}=x_{new}) 
                                        &= \int_{ -\infty}^{\infty}  P(X_{old}=[x_{new}, \tilde{x}_{0}]) d{\tilde{x}_0} \\
                                        &= \int_{ -\infty}^{\infty}  P(X_{new}=x_{new}, x_0=\tilde{x}_{0}) d{\tilde{x}_0}
                                    \end{aligned}
                                    \end{equation}
                                </p>

                                <h3>2.协方差矩阵、信息矩阵和边缘化</h3>
								<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
									假设变量$(x,y)$的概率密度函数符合均值$\mu$，协方差$\Sigma$的高斯分布，具有如下的矩阵形式：
									\begin{equation}
									p(x,y) = \mathcal{N} (
										\begin{bmatrix}
											\textbf{$\mu_x$} \\
											\textbf{$\mu_y$}
										\end{bmatrix},
										\begin{bmatrix}
											\textbf{$\Sigma_{xx}$} & \textbf{$\Sigma_{xy}$} \\
											\textbf{$\Sigma_{yx}$} & \textbf{$\Sigma_{yy}$}
										\end{bmatrix} 
										)
									\end{equation}
									那么边缘化就非常好操作了，对于变量$y$，其对应的子块$\mu_y$和$\Sigma_{yy}$就是边缘化掉变量$x$后，$y$的均值和协方差。
									
									但是在很多基于优化的vins中，我们对于变量的分布是以信息矩阵$\varLambda$和信息向量$\eta$的形式给出的，具有如下形式：
									\begin{equation}
										p(x,y) = \mathcal{N} (
											\varLambda^{-1}
											\begin{bmatrix}
												\textbf{$\eta_x$} \\
												\textbf{$\eta_y$}
											\end{bmatrix},
											\begin{bmatrix}
												\textbf{$\varLambda_{xx}$} & \textbf{$\varLambda_{xy}$} \\
												\textbf{$\varLambda_{yx}$} & \textbf{$\varLambda_{yy}$}
											\end{bmatrix}^{-1}
											)
									\end{equation}
									这时候我们想进行边缘化得到变量$y$的信息矩阵就没有那么直观了。舒尔补分解协方差矩阵并求逆，可以得到信息矩阵和协方差矩阵的关系：
									\begin{equation}
										\begin{split}
											\begin{aligned}
										\begin{bmatrix}
											\textbf{$\varLambda_{xx}$} & \textbf{$\varLambda_{xy}$} \\
											\textbf{$\varLambda_{yx}$} & \textbf{$\varLambda_{yy}$}
										\end{bmatrix}
										&=
										\begin{bmatrix}
											\textbf{$\Sigma_{xx}$} & \textbf{$\Sigma_{xy}$} \\
											\textbf{$\Sigma_{yx}$} & \textbf{$\Sigma_{yy}$}
										\end{bmatrix} ^{-1} \\
										&=
										\begin{bmatrix}
											\textbf{1} & \textbf{0} \\
											\textbf{-$\Sigma_{yy}^{-1}\Sigma_{yx}$} & \textbf{1}
										\end{bmatrix}     
										\begin{bmatrix}
											\textbf{$(\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})^{-1}$} & \textbf{0} \\
											\textbf{0} & \textbf{$\Sigma_{yy}^{-1}$}
										\end{bmatrix}
										\begin{bmatrix}
											\textbf{1} & \textbf{-$\Sigma_{xy}\Sigma_{yy}^{-1}$} \\
											\textbf{0} & \textbf{1}
										\end{bmatrix}  \\
										&=
										\begin{bmatrix}
											\textbf{$(\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})^{-1}$} & \textbf{$-(\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})^{-1}\Sigma_{xy}\Sigma_{yy}^{-1}$} \\
											\textbf{$-\Sigma_{yy}^{-1}\Sigma_{yx}(\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})^{-1}$} & \textbf{$\Sigma_{yy}^{-1} + \Sigma_{yy}^{-1}\Sigma_{yx}(\Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx})^{-1}\Sigma_{xy}\Sigma_{yy}^{-1}$}
										\end{bmatrix}    
									\end{aligned}
									\end{split}
									\end{equation}
									由此可得，变量$y$的信息矩阵，即协方差$\Sigma_{yy}$的逆为：
									\begin{equation}
										\label{info}
										\begin{split}
											\begin{aligned}
										\Sigma_{yy}^{-1} = \textbf{$\varLambda_{yy} - \varLambda_{yx}\varLambda_{xx}^{-1}\varLambda_{xy}$}
									\end{aligned}
									\end{split}
									\end{equation}
									
								<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
									我们知道，对于上述高斯分布，我们可以采用舒尔补进行分解，得到边缘概率密度函数和条件概率密度函数。
									\begin{equation}
									\label{schur}
									\begin{split}
									\begin{aligned}
										p(x,y) &= p(x|y)p(y) \\
										p(x|y) &= \mathcal{N}(\mu_x + \Sigma_{xy}\Sigma_{yy}^{-1}(y-\mu_y), \Sigma_{xx} - \Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx}) \\
										p(y) &= \mathcal{N} (\mu_y, \Sigma_{yy})
									\end{aligned}
									\end{split}
									\end{equation}
									这时我们对照公式Eq(\ref{schur})和公式Eq(\ref{info})，会发现条件概率$P(x|y)$的协方差就是$\varLambda_{xx}^{-1}$！也就是说，我们如果直接从信息矩阵中取块，得到的是变量的条件概率分布的信息矩阵\cite{pa}。
								</p>
								<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
									这引出了一个非常有趣的现象：边际概率对于协方差矩阵的操作是很容易的，对于信息矩阵不好操作，而条件概率恰好相反。
								</p>

								<h3>3.边缘化的平方根方法</h3>
								<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
									上节中我们得到，直接对信息矩阵进行舒尔补分解是可以实现边缘化的，这一节我们学习边缘化的平方根（Square Root）方法。
									平方根方法的引入源自在求解非线性最小二乘问题时，信息矩阵通常是形如$H=J^TJ$来进行构造的，如高斯牛顿方法和LM方法。如果我们对$J$进行QR分解，有
									\begin{equation}
										\label{qr}
										\begin{split}
										\begin{aligned}
											\textbf{J} = \begin{bmatrix}
												\textbf{Q}_1 & \textbf{Q}_2
											\end{bmatrix} ^T
											\begin{bmatrix}
												\textbf{R} \\ \textbf{0}
											\end{bmatrix},  
											\quad with \quad \textbf{R} = \begin{bmatrix}
												R & T \\
												0 & P
											\end{bmatrix}
										\end{aligned}
										\end{split}
										\end{equation}
									那么对于信息矩阵有
									\begin{equation}
										\label{squareroot}
										\begin{split}
										\begin{aligned}
											\textbf{H} = \textbf{R}^T\textbf{R} = 
											\begin{bmatrix}
												R & T \\
												0 & P
											\end{bmatrix} ^T
											\begin{bmatrix}
												R & T \\
												0 & P
											\end{bmatrix}
											=
											\begin{bmatrix}
												R^TR & R^TT \\
												T^TR & P^TP + T^TT
											\end{bmatrix} ^T
										\end{aligned}
										\end{split}
									\end{equation}
									对照公式Eq(\ref{info})和公式Eq(\ref{squareroot})，我们发现恰好有$\Sigma_{yy}^{-1} = P^TP$。
									对于QR分解，我们知道，它得到的是一个正交矩阵和一个上三角矩阵的乘积，因此我们想要边缘化的子变量部分必须要放在变量向量的头部，才能直接使用上述方法进行边缘化。
									</p>
									<p style="text-indent:2em; margin-top:0em;margin-bottom:0em;font-size:0.9em;">
									
									实际上，我们进行边缘化的时候并不需要真的要求出正交矩阵$\textbf{Q}$，我们的目的是将求出矩阵$\textbf{R}$，而Givens Rotation告诉我们，只需要不断地左乘Givens旋转矩阵，即可将消去矩阵$\textbf{J}$的下三角中的非零元素。
								</p>

								<h3>4.参考资料</h3>
								<ul>
									<li style="font-size:1em">
										 Walter M R, Eustice R M, Leonard J J. Exactly sparse extended information filters for feature-based SLAM[J].
										The International Journal of Robotics Research, 2007, 26(4): 335-359.
									</li>
									<li style="font-size:1em"> 
										Demmel N, Schubert D, Sommer C, et al. Square Root Marginalization for Sliding-Window Bundle Adjustment[C]//
									Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 13260-13268.
									</li>
									<li style="font-size:1em"> 
									Demmel N, Sommer C, Cremers D, et al. Square Root Bundle Adjustment for Large-Scale Reconstruction[C]//
									Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 11723-11732.
									</li>
									<li style="font-size:1em">
										Barfoot T D. State estimation for robotics[J]. 2021. 
									</li>
									<li style="font-size:1em">
										Dellaert F, Kaess M. Factor graphs for robot perception[J]. Foundations and Trends® in Robotics, 2017, 6(1-2): 1-139.
									</li>
								<!-- \end{itemize} -->
								</p>
								</ul>
						</div>
					</section>
            </div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/jquery.scrolly.min.js"></script>
			<script src="../../assets/js/jquery.scrollex.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

	</body>
</html>